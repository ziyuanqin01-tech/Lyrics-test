{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L5dLwo3X8NX",
        "outputId": "df90613d-c700-4b0b-e9d3-4a87463d7852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  的: 9 1\n",
            "least frequent word:\n",
            "  炽热: 1 2\n"
          ]
        }
      ],
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"月如歌.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"如果可以.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3nh9xoAZ1s8",
        "outputId": "c16e012f-4fe4-46ba-d7f6-7fc25cc0023e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  你: 25 1\n",
            "least frequent word:\n",
            "  决定: 1 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"太阳与地球.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG3Bu5fXbv92",
        "outputId": "bf063170-dab6-47cc-db23-e9938c860eef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  的: 12 1\n",
            "least frequent word:\n",
            "  一直: 1 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"慢一点.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XGUQ_KtcWFt",
        "outputId": "c5205f11-659c-48cc-a650-5a099ed39460"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  慢: 12 1\n",
            "least frequent word:\n",
            "  见: 1 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"你曾是少年.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "\n",
        "if use_jieba:\n",
        "        chinese_punctuation = '。，、；：！？「」\"\"（）《》【】～'\n",
        "        words = [w for w in words if w not in chinese_punctuation]\n",
        "else:\n",
        "        words = [c for c in text if c.strip() and c not in '。，、；：！？「」\"\"（）《》【】～']\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2DwVA53ctj_",
        "outputId": "ef482c87-0ee5-4500-a8d0-dc1df92cfc55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  的: 10 1\n",
            "least frequent word:\n",
            "  陌生人: 1 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"起风了.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "\n",
        "if use_jieba:\n",
        "        chinese_punctuation = '。，、；：！？「」\"\"（）《》【】～'\n",
        "        words = [w for w in words if w not in chinese_punctuation]\n",
        "else:\n",
        "        words = [c for c in text if c.strip() and c not in '。，、；：！？「」\"\"（）《》【】～']\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKCFFC6zdg4q",
        "outputId": "2216c80e-d1fd-4405-93f3-cf4a435c4990"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  的: 16 1\n",
            "least frequent word:\n",
            "  随风: 1 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"演员.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "\n",
        "if use_jieba:\n",
        "        chinese_punctuation = '。，、；：！？「」\"\"（）《》【】～'\n",
        "        words = [w for w in words if w not in chinese_punctuation]\n",
        "else:\n",
        "        words = [c for c in text if c.strip() and c not in '。，、；：！？「」\"\"（）《》【】～']\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_sV4KwId7_R",
        "outputId": "48e710df-d6eb-4d29-87f8-6fcdd65c99a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  的: 21 1\n",
            "least frequent word:\n",
            "  最后: 1 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"年轮.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "\n",
        "if use_jieba:\n",
        "        chinese_punctuation = '。，、；：！？「」\"\"（）《》【】～'\n",
        "        words = [w for w in words if w not in chinese_punctuation]\n",
        "else:\n",
        "        words = [c for c in text if c.strip() and c not in '。，、；：！？「」\"\"（）《》【】～']\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kOYvK-YeQ3W",
        "outputId": "61d03454-746a-4414-cb5e-81eb5abba469"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  的: 16 1\n",
            "least frequent word:\n",
            "  清晨: 1 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"丁香花.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "\n",
        "if use_jieba:\n",
        "        chinese_punctuation = '。，、；：！？「」\"\"（）《》【】～'\n",
        "        words = [w for w in words if w not in chinese_punctuation]\n",
        "else:\n",
        "        words = [c for c in text if c.strip() and c not in '。，、；：！？「」\"\"（）《》【】～']\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2h5Yos5emnx",
        "outputId": "1dbf93c0-af56-47b9-80e2-eaa533797762"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  你: 23 1\n",
            "least frequent word:\n",
            "  它: 1 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"成都.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "use_jieba = True\n",
        "if use_jieba:\n",
        "        words = list(jieba.cut(text, cut_all=False))\n",
        "else:\n",
        "        words = list(text)\n",
        "words = [w.strip() for w in words if w.strip()]\n",
        "\n",
        "if use_jieba:\n",
        "        chinese_punctuation = '。，、；：！？「」\"\"（）《》【】～'\n",
        "        words = [w for w in words if w not in chinese_punctuation]\n",
        "else:\n",
        "        words = [c for c in text if c.strip() and c not in '。，、；：！？「」\"\"（）《》【】～']\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "id": "m2ylGfJwfDsl",
        "outputId": "ff3b91c5-6db8-42dd-d3ec-8361b758790d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  的: 16 1\n",
            "least frequent word:\n",
            "  门口: 1 2\n"
          ]
        }
      ]
    }
  ]
}