{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO8dmUzeRFDa",
        "outputId": "b445a859-9084-4ad2-f10f-6f265f075469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  my: 19 2\n",
            "least frequent word:\n",
            "  dip: 1 3\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"happylittlepill.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"lover.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26ESj3kaRybx",
        "outputId": "4c85b20d-4dc9-48d7-cf06-a3afaaabfbdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  my: 24 2\n",
            "least frequent word:\n",
            "  darling: 1 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"galwaygirl.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVdU7b1YR3WS",
        "outputId": "617382b2-5c46-4891-f748-393fc8768552"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  my: 47 2\n",
            "least frequent word:\n",
            "  perfect: 1 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"lover.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtKAWVjIR7Za",
        "outputId": "f9c48461-4819-4b98-cefe-714c0b70c0d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  my: 24 2\n",
            "least frequent word:\n",
            "  darling: 1 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"sheusedtobemine.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMvI1yFQSGhf",
        "outputId": "6cbc3715-19ce-448c-8a55-66252c94a75e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  and: 12 3\n",
            "least frequent word:\n",
            "  been: 1 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"youngandbeautiful.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugDGv0oDSuLH",
        "outputId": "f4dfb045-dbc7-4d86-ddf2-064f3a78821f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  you: 23 3\n",
            "least frequent word:\n",
            "  not: 1 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"deadman.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap5nKwQnTAdO",
        "outputId": "2c6bc83b-a747-4dee-b1cf-9fe8134bb63d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  i: 15 1\n",
            "least frequent word:\n",
            "  without: 1 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"goldenhour.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siyuobKJUMVu",
        "outputId": "7fe8a378-a57b-4a25-c715-04ce2aa2d655"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  the: 10 3\n",
            "least frequent word:\n",
            "  angel: 1 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"mysteryoflove.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlRXDcG7Uwbh",
        "outputId": "1a4fb1db-6d6e-4ea0-d082-866d986229c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  oh: 12 2\n",
            "least frequent word:\n",
            "  breath: 1 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "file_path=\"alliwantforchristmasisyou.txt\"\n",
        "file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text_lower=text.lower()\n",
        "tokens = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text_lower)\n",
        "words=tokens\n",
        "word_counts = Counter(words)\n",
        "most_common = word_counts.most_common(1)\n",
        "print(\"most frequent word:\")\n",
        "for word, count in most_common:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")\n",
        "\n",
        "all_sorted = word_counts.most_common()\n",
        "least_frequent_words = all_sorted[-1:] if all_sorted else []\n",
        "print(\"least frequent word:\")\n",
        "for word, count in least_frequent_words:\n",
        "    word_length = len(word)\n",
        "    print(f\"  {word}: {count} {word_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7gyqcXGV2zy",
        "outputId": "ca49e9fe-32f3-4866-9e6e-6d0f6829bb6d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most frequent word:\n",
            "  you: 16 3\n",
            "least frequent word:\n",
            "  door: 1 4\n"
          ]
        }
      ]
    }
  ]
}